# .gitlab-ci.yml
# Enhanced GitLab CI configuration for CSV with Headers

spec:
  inputs:
    environment:
      type: string
      description: "Select the Grid environment to deploy to"
      default: "cabgridmgr"
      options:
        - "cabgridmgr"
        - "etsl"
        - "nhq"
        - "enterprise"
    record_type:
      type: string
      description: "Select the DNS record type"
      default: "a_record"
      options:
        - "a_record"
        - "aaaa_record"
        - "cname_record"
        - "fixed_address"
        - "host_record"
        - "mx_record"
        - "network"
        - "ptr_record"
        - "srv_record"
        - "txt_record"
        - "nios_zone"
---

image: $CI_REGISTRY_IMAGE/infoblox-runner:latest

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"

  OPERATION_TYPE:
    value: "add"
    options:
      - "add"
      - "delete"
    description: "Select operation: add (present state) or delete (absent state)"

  # CSV Data Input with Headers
  CSV_DATA:
    value: ""
    description: |
      Paste CSV data WITH HEADERS for the selected record type.
      
      A Record Example:
      name,ipv4addr,view,comment,Environment,Owner,Location,Department
      webserver1.example.com,192.168.1.10,production,Web server,prod,teamA,DataCenter1,IT
      
      Max: 10000 characters.

stages:
  - build-container
  - file-processing
  - pre-implementation
  - deploy
  - post-implementation

workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == 'web'
      when: always
    - when: never

.common_script: &common_script
  - |
    echo "Starting Common Script"
    echo "Environment input: $[[ inputs.environment ]]"
    echo "Record type input: $[[ inputs.record_type ]]"
    
    case "$[[ inputs.environment ]]" in
      cabgridmgr)
        export GRID_URL="https://10.74.3.80"
        export GRID_HOST="cabgridmgr.amfam.com"
        export GRID_HOST_IP="10.74.3.80"
        export INFOBLOX_USERNAME="${CAB_INFOBLOX_USER}"
        export INFOBLOX_PASSWORD="${CAB_INFOBLOX_PASS}"
        ;;
      etsl)
        export GRID_URL="https://172.24.125.10"
        export GRID_HOST="172.24.125.10"
        export GRID_HOST_IP="172.24.125.10"
        export INFOBLOX_USERNAME="${ETSL_INFOBLOX_USER}"
        export INFOBLOX_PASSWORD="${ETSL_INFOBLOX_PASS}"
        ;;
      nhq)
        export GRID_URL="https://10.74.70.63"
        export GRID_HOST="gridmgr.amfam.com"
        export GRID_HOST_IP="10.74.70.63"
        export INFOBLOX_USERNAME="${NHQ_INFOBLOX_USER}"
        export INFOBLOX_PASSWORD="${NHQ_INFOBLOX_PASS}"
        ;;
      enterprise)
        export GRID_URL="https://10.186.164.10"
        export GRID_HOST="entgridmgr.amfam.com"
        export GRID_HOST_IP="10.186.164.10"
        export INFOBLOX_USERNAME="${ENT_INFOBLOX_USER}"
        export INFOBLOX_PASSWORD="${ENT_INFOBLOX_PASS}"
        ;;
      *)
        echo "Unknown environment: $[[ inputs.environment ]]"
        exit 1
        ;;
    esac
    
    export RECORD_TYPE="$[[ inputs.record_type ]]"
    echo "Selected environment: $[[ inputs.environment ]]"
    echo "Selected record type: $RECORD_TYPE"
    echo "Using Grid URL: $GRID_URL"
    echo "Using Grid Host: $GRID_HOST"

build_container:
  stage: build-container
  image:
    name: gcr.io/kaniko-project/executor:v1.9.0-debug
    entrypoint: [""]
  script:
    - |
      mkdir -p /kaniko/.docker
      echo "{\"auths\":{\"$CI_REGISTRY\":{\"auth\":\"$(printf "%s:%s" "${CI_REGISTRY_USER}" "${CI_REGISTRY_PASSWORD}" | base64 | tr -d '\n')\"}}}" > /kaniko/.docker/config.json
      
      echo "Building custom Infoblox runner container with Kaniko..."
      
      /kaniko/executor \
        --context "${CI_PROJECT_DIR}" \
        --dockerfile "${CI_PROJECT_DIR}/Dockerfile" \
        --destination "${CI_REGISTRY_IMAGE}/infoblox-runner:latest" \
        --cache=true \
        --cache-ttl=168h
      
      echo "Container built and pushed successfully"
  rules:
    - if: $CI_PIPELINE_SOURCE == 'web'
      changes:
        - Dockerfile
      when: always
    - if: $CI_PIPELINE_SOURCE == 'web'
      when: manual
    - when: never
  tags:
    - aws-eks-elz-ent-ens-01-01

file_processing:
  stage: file-processing
  script:
    - *common_script
    - |
      echo "=========================================="
      echo "  INFOBLOX RECORD PROCESSING PIPELINE"
      echo "=========================================="
      echo "Target Grid: $GRID_HOST"
      echo "Record Type: $RECORD_TYPE"
      echo "Operation: $OPERATION_TYPE"
      echo "=========================================="
      echo ""
      
      echo "[1/5] Installing dependencies..."
      pip3 install pandas openpyxl >/dev/null 2>&1
      
      echo "[2/5] Validating input data..."
      if [ -z "$CSV_DATA" ]; then
        echo ""
        echo "ERROR: CSV_DATA is empty!"
        echo ""
        echo "Please provide CSV data with headers."
        echo ""
        echo "Expected format:"
        echo "----------------------------------------"
        echo "name,ipv4addr,view,comment,Environment,Owner,Location,Department"
        echo "webserver1.example.com,192.168.1.10,production,Web server,prod,teamA,DataCenter1,IT"
        echo "----------------------------------------"
        echo ""
        exit 1
      fi
      
      char_count=$(echo -n "$CSV_DATA" | wc -c)
      echo "   Input size: $char_count characters"
      
      CHAR_LIMIT=10000
      if [ $char_count -gt $CHAR_LIMIT ]; then
        echo ""
        echo "ERROR: Input exceeds character limit!"
        echo "   Current: $char_count characters"
        echo "   Maximum: $CHAR_LIMIT characters"
        echo "   Excess: $((char_count - CHAR_LIMIT)) characters"
        echo ""
        exit 1
      fi
      
      echo "[3/5] Saving CSV data..."
      mkdir -p input
      csv_file="input/${RECORD_TYPE}.csv"
      echo "$CSV_DATA" > "$csv_file"
      
      # NEW: Debug CSV content
      echo "DEBUG: Raw CSV content:"
      echo "----------------------------------------"
      cat "$csv_file" | head -5
      echo "----------------------------------------"
      
      # NEW: Validate CSV format
      echo "DEBUG: Checking CSV structure..."
      python3 -c "import csv; f=open('$csv_file','r'); reader=csv.DictReader(f,delimiter=','); print('Detected fields:',list(reader.fieldnames)); [print(f'Row {i+2}:',dict(row)) for i,row in enumerate(reader) if i<2]; f.close()"
      
      echo "[4/5] Input data preview:"
      echo "----------------------------------------"
      head -5 "$csv_file"
      if [ $(wc -l < "$csv_file") -gt 5 ]; then
        echo "... (showing first 5 lines)"
      fi
      echo "----------------------------------------"
      echo ""
      
      echo "[5/5] Processing records..."
      python3 infoblox_mvp1/utils/infoblox_record_processor.py \
        "$csv_file" \
        --grid-host "$GRID_HOST" \
        --record-type "$RECORD_TYPE" \
        --output-dir "infoblox_mvp1/prod_changes"
      
      if [ $? -ne 0 ]; then
        echo "  [ERROR] Failed to process $RECORD_TYPE"
        exit 1
      fi
      
      json_file="infoblox_mvp1/prod_changes/$GRID_HOST/${RECORD_TYPE}.json"
      if [ -f "$json_file" ]; then
        processed_count=$(python3 -c "import json; print(len(json.load(open('$json_file'))))")
        echo ""
        echo "=========================================="
        echo "  PROCESSING COMPLETE"
        echo "=========================================="
        echo "Processed: $processed_count records"
        echo "Output file: $json_file"
        echo "Record type: $RECORD_TYPE"
        echo "Target grid: $GRID_HOST"
        echo ""
        
        echo "JSON output preview:"
        echo "----------------------------------------"
        python3 -c "import json; import sys; data=json.load(open('$json_file')); print(json.dumps(data[:2] if len(data) > 2 else data, indent=2))"
        if [ $processed_count -gt 2 ]; then
          echo "... (showing first 2 records)"
        fi
        echo "----------------------------------------"
      else
        echo "[ERROR] JSON output file not created"
        exit 1
      fi
      
      echo "=========================================="

  artifacts:
    paths:
      - infoblox_mvp1/prod_changes/
      - input/
    expire_in: 1 hour
  tags:
    - aws-eks-elz-ent-ens-01-01

server_connection_test:
  stage: pre-implementation
  script:
    - *common_script
    - |
      echo "=== Network Connectivity Test ==="
      echo "Target Grid: $GRID_HOST ($GRID_HOST_IP)"
      
      if ! command -v curl > /dev/null 2>&1; then
        echo "Installing curl..."
        apt-get update && apt-get install -y curl
      fi
      
      echo "Testing connectivity to $GRID_URL..."
      if curl -s -k --head --request GET "$GRID_URL/ui" | grep -E "200 OK|302 Found" > /dev/null; then
        echo "[OK] Grid manager is reachable"
        exit 0
      else
        echo "[ERROR] Grid manager is unreachable"
        echo "This may indicate network restrictions on the GitLab Runner."
        exit 1
      fi
  tags:
    - aws-eks-elz-ent-ens-01-01

pre_check:
  stage: pre-implementation
  script:
    - *common_script
    - |
      echo "=== Pre-Check Validation with Robot Framework ==="
      echo "Grid: $GRID_HOST"
      echo "Record Type: $RECORD_TYPE"

      export infoblox_username="$INFOBLOX_USERNAME"
      export infoblox_password="$INFOBLOX_PASSWORD"

      json_file="infoblox_mvp1/prod_changes/$GRID_HOST/${RECORD_TYPE}.json"

      if [ ! -f "$json_file" ]; then
        echo "[ERROR] JSON file not found: $json_file"
        exit 1
      fi

      echo "Installing Robot Framework..."
      pip3 install robotframework >/dev/null 2>&1

      echo "Running pre-check validation with Robot Framework..."

      # Determine which test suite to run based on record type
      case "$RECORD_TYPE" in
        a_record)
          test_suite="infoblox_mvp1/tests/pre_check/a_record_validation.robot"
          ;;
        cname_record)
          test_suite="infoblox_mvp1/tests/pre_check/cname_record_validation.robot"
          ;;
        network)
          test_suite="infoblox_mvp1/tests/pre_check/network_validation.robot"
          ;;
        *)
          # Run all pre-check tests for unknown types
          test_suite="infoblox_mvp1/tests/pre_check/"
          ;;
      esac

      echo "Running test suite: $test_suite"

      # Run Robot Framework tests
      robot \
        --variable GRID_HOST:$GRID_HOST \
        --variable RECORD_TYPE:$RECORD_TYPE \
        --outputdir infoblox_mvp1/robot_reports/pre_check \
        --name "Pre-Check Validation - $RECORD_TYPE" \
        --loglevel INFO \
        "$test_suite"

      robot_exit_code=$?

      if [ $robot_exit_code -ne 0 ]; then
        echo "[ERROR] Pre-check validation failed"
        echo "Check the Robot Framework report for details"
        exit 1
      fi

      echo "[OK] Pre-check validation passed"

      echo ""
      echo "Merging with historical test runs..."
      python3 infoblox_mvp1/utils/robot/merge_reports.py pre_check 20

      if [ $? -eq 0 ]; then
        echo "[OK] Test history merged successfully"
        echo "  - Current run: infoblox_mvp1/robot_reports/pre_check/report.html"
        echo "  - Combined history: infoblox_mvp1/robot_reports/pre_check/combined_report.html"
      else
        echo "[WARN] Failed to merge test history (non-critical)"
      fi

  artifacts:
    when: always
    paths:
      - infoblox_mvp1/robot_reports/pre_check/
    reports:
      junit: infoblox_mvp1/robot_reports/pre_check/output.xml
    expire_in: 1 week
  tags:
    - aws-eks-elz-ent-ens-01-01

json_validation:
  stage: pre-implementation
  script:
    - *common_script
    - |
      echo "=== JSON Validation ==="
      echo "Record type: $RECORD_TYPE"
      
      json_file="infoblox_mvp1/prod_changes/$GRID_HOST/${RECORD_TYPE}.json"
      
      # Check if file exists
      if [ ! -f "$json_file" ]; then
        echo "[ERROR] JSON file not found: $json_file"
        exit 1
      fi
      
      # Check if file is empty
      if [ ! -s "$json_file" ]; then
        echo "[ERROR] JSON file is empty"
        exit 1
      fi
      
      # Validate JSON
      if python3 -c "import json; json.load(open('$json_file'))"; then
        echo "✓ $json_file is valid JSON"
        record_count=$(python3 -c "import json; print(len(json.load(open('$json_file'))))")
        echo "  Records: $record_count"
      else
        echo "✗ $json_file is NOT valid JSON"
        exit 1
      fi
      
      echo ""
      echo "[OK] Validation passed"
  tags:
    - aws-eks-elz-ent-ens-01-01

run_ansible_playbook:
  stage: deploy
  needs:
    - file_processing
  script:
    - *common_script
    - |
      echo "=========================================="
      echo "  ANSIBLE DEPLOYMENT"
      echo "=========================================="
      echo "Grid: $GRID_HOST"
      echo "Record Type: $RECORD_TYPE"
      echo "Operation: $OPERATION_TYPE"
      echo "=========================================="
      echo ""
      
      # Verify the JSON file exists and get absolute path
      json_file="infoblox_mvp1/prod_changes/$GRID_HOST/${RECORD_TYPE}.json"
      
      if [ ! -f "$json_file" ]; then
        echo "[ERROR] JSON file not found: $json_file"
        echo "Listing directory contents:"
        ls -la infoblox_mvp1/prod_changes/
        exit 1
      fi
      
      # Get absolute path for verification only
      JSON_FILE_PATH="$(pwd)/$json_file"
      echo "JSON file found at: $JSON_FILE_PATH"
      echo ""
      
      # Set relative path for Ansible playbook (relative to playbooks directory)
      ANSIBLE_JSON_PATH="../prod_changes/$GRID_HOST/${RECORD_TYPE}.json"
      
      export ANSIBLE_HOST_KEY_CHECKING=False
      export ANSIBLE_DEPRECATION_WARNINGS=False
      
      echo "Installing dependencies..."
      pip3 install --upgrade pip >/dev/null 2>&1
      pip3 install infoblox-client netaddr pyyaml requests urllib3 >/dev/null 2>&1
      
      mkdir -p ~/.ansible/collections/ansible_collections/infoblox/nios_modules/plugins/modules
      
      cat > provider_config.json << EOF
      {
        "clean_provider": {
          "host": "$GRID_HOST_IP",
          "username": "$INFOBLOX_USERNAME",
          "password": "$INFOBLOX_PASSWORD",
          "wapi_version": "2.13.4",
          "max_retries": 3,
          "max_results": 1000,
          "validate_certs": false,
          "http_request_timeout": 999999
        },
        "grid_host": "$GRID_HOST"
      }
      EOF
      
      echo ""
      
      playbook_file="infoblox_mvp1/playbooks/${RECORD_TYPE}.yml"
      
      if [ ! -f "$playbook_file" ]; then
        echo "[ERROR] Playbook not found: $playbook_file"
        exit 1
      fi
      
      echo "Executing playbook: $playbook_file"
      echo "Passing json_file variable: $ANSIBLE_JSON_PATH"
      echo ""
      
      ansible-playbook -i localhost, \
        --extra-vars "@provider_config.json" \
        -e "operation=$OPERATION_TYPE" \
        -e "json_file=$ANSIBLE_JSON_PATH" \
        -e "ansible_connection=local" \
        -e "ansible_python_interpreter=/usr/bin/python3" \
        "$playbook_file" \
        --verbose
      
      playbook_result=$?
      
      rm -f provider_config.json
      
      if [ $playbook_result -eq 0 ]; then
        echo ""
        echo "[OK] Deployment successful"
      else
        echo ""
        echo "[ERROR] Deployment failed"
        exit 1
      fi
      
      echo "=========================================="

  tags:
    - aws-eks-elz-ent-ens-01-01
  allow_failure: false

post_implementation:
  stage: post-implementation
  script:
    - *common_script
    - |
      echo "=== Post-Implementation Verification with Robot Framework ==="
      echo "Grid: $GRID_HOST"
      echo "Record Type: $RECORD_TYPE"
      echo "Operation: $OPERATION_TYPE"

      export infoblox_username="$INFOBLOX_USERNAME"
      export infoblox_password="$INFOBLOX_PASSWORD"

      json_file="infoblox_mvp1/prod_changes/$GRID_HOST/${RECORD_TYPE}.json"

      if [ -f "$json_file" ]; then
        record_count=$(python3 -c "import json; print(len(json.load(open('$json_file'))))")
        echo "Records processed: $record_count"
      fi

      echo ""
      echo "Installing Robot Framework..."
      pip3 install robotframework >/dev/null 2>&1

      echo "Running post-deployment verification with Robot Framework..."

      # Determine which test suite to run based on record type
      case "$RECORD_TYPE" in
        a_record)
          test_suite="infoblox_mvp1/tests/post_check/a_record_verification.robot"
          ;;
        cname_record)
          test_suite="infoblox_mvp1/tests/post_check/cname_record_verification.robot"
          ;;
        network)
          test_suite="infoblox_mvp1/tests/post_check/network_verification.robot"
          ;;
        *)
          # Run all post-check tests for unknown types
          test_suite="infoblox_mvp1/tests/post_check/"
          ;;
      esac

      echo "Running test suite: $test_suite"

      # Run Robot Framework tests
      robot \
        --variable GRID_HOST:$GRID_HOST \
        --variable RECORD_TYPE:$RECORD_TYPE \
        --outputdir infoblox_mvp1/robot_reports/post_check \
        --name "Post-Deployment Verification - $RECORD_TYPE" \
        --loglevel INFO \
        "$test_suite"

      robot_exit_code=$?

      if [ $robot_exit_code -ne 0 ]; then
        echo "[WARNING] Post-deployment verification failed"
        echo "Check the Robot Framework report for details"
      else
        echo "[OK] Post-deployment verification passed"
      fi

      echo ""
      echo "[OK] Deployment complete"
      echo ""
      echo "Summary:"
      echo "  - Grid: $GRID_HOST"
      echo "  - Record Type: $RECORD_TYPE"
      echo "  - Operation: $OPERATION_TYPE"
      echo "  - Status: Success"
      echo ""
      echo "Robot Framework Reports:"
      echo "  - HTML Report: infoblox_mvp1/robot_reports/post_check/report.html"
      echo "  - Log: infoblox_mvp1/robot_reports/post_check/log.html"

      echo ""
      echo "Merging with historical test runs..."
      python3 infoblox_mvp1/utils/robot/merge_reports.py post_check 20

      if [ $? -eq 0 ]; then
        echo "[OK] Test history merged successfully"
        echo "  - Current run: infoblox_mvp1/robot_reports/post_check/report.html"
        echo "  - Combined history: infoblox_mvp1/robot_reports/post_check/combined_report.html"
      else
        echo "[WARN] Failed to merge test history (non-critical)"
      fi

      echo ""
      echo "=== File Cleanup and Repository Update ==="

      # Pull latest changes
      git pull origin main

      # Run file cleanup script
      echo "Running file cleanup for $GRID_HOST..."
      python3 infoblox_mvp1/utils/clearfilecontent.py

      # Configure git
      git config --global user.name "GitLab_Runner"
      git config --global user.email "ens@amfam.com"

      # Stage all changes
      git add *

      # Check if there are changes to commit
      if [[ -n $(git status --porcelain) ]]; then
        git commit -m "post-implementation cleanup for $GRID_HOST environment"
        git remote set-url origin "https://GitLab_Runner:${GITLAB_CI_TOKEN}@${CI_SERVER_HOST}/${CI_PROJECT_PATH}.git"
        git push origin HEAD:main
        echo "[OK] Changes committed and pushed for $GRID_HOST"
      else
        echo "[INFO] No changes to commit for $GRID_HOST"
      fi

      echo "[OK] Post-implementation tasks completed successfully for $GRID_HOST"

  artifacts:
    when: always
    paths:
      - infoblox_mvp1/robot_reports/post_check/
    reports:
      junit: infoblox_mvp1/robot_reports/post_check/output.xml
    expire_in: 1 week
  tags:
    - aws-eks-elz-ent-ens-01-01
  when: on_success
  needs:
    - run_ansible_playbook
