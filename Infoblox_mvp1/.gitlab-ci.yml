# .gitlab-ci-enhanced.yml
# Enhanced GitLab CI configuration with ExecutionCounter and Historical Report Tracking

spec:
  inputs:
    environment:
      type: string
      description: "Select the Grid environment to deploy to"
      default: "cabgridmgr"
      options:
        - "cabgridmgr"
        - "etsl"
        - "nhq"
        - "enterprise"
    record_type:
      type: string
      description: "Select the DNS record type"
      default: "a_record"
      options:
        - "a_record"
        - "aaaa_record"
        - "cname_record"
        - "fixed_address"
        - "host_record"
        - "mx_record"
        - "network"
        - "ptr_record"
        - "srv_record"
        - "txt_record"
        - "nios_zone"
    operation_type:
      type: string
      description: "Select operation: add (present state) or delete (absent state)"
      default: "add"
      options:
        - "add"
        - "delete"

---
image: $CI_REGISTRY_IMAGE/infoblox-runner:latest

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"

  # CSV Data Input with Headers
  CSV_DATA:
    value: ""
    description: |
      Paste CSV data WITH HEADERS for the selected record type.

      A Record Example:
      name,ipv4addr,view,comment,Environment,Owner,Location,Department
      webserver1.example.com,192.168.1.10,production,Web server,prod,teamA,DataCenter1,IT

      Max: 10000 characters.

stages:
  - build-container
  - file-processing
  - pre-implementation
  - deploy
  - post-implementation

workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == 'web'
      when: always
    - when: never

.common_script: &common_script
  - |
    echo "Starting Common Script"
    echo "Environment input: $[[ inputs.environment ]]"
    echo "Record type input: $[[ inputs.record_type ]]"

    case "$[[ inputs.environment ]]" in
      cabgridmgr)
        export GRID_URL="https://10.74.3.80"
        export GRID_HOST="cabgridmgr.amfam.com"
        export GRID_HOST_IP="10.74.3.80"
        export INFOBLOX_USERNAME="${CAB_INFOBLOX_USER}"
        export INFOBLOX_PASSWORD="${CAB_INFOBLOX_PASS}"
        ;;
      etsl)
        export GRID_URL="https://172.24.125.10"
        export GRID_HOST="172.24.125.10"
        export GRID_HOST_IP="172.24.125.10"
        export INFOBLOX_USERNAME="${ETSL_INFOBLOX_USER}"
        export INFOBLOX_PASSWORD="${ETSL_INFOBLOX_PASS}"
        ;;
      nhq)
        export GRID_URL="https://10.74.70.63"
        export GRID_HOST="gridmgr.amfam.com"
        export GRID_HOST_IP="10.74.70.63"
        export INFOBLOX_USERNAME="${NHQ_INFOBLOX_USER}"
        export INFOBLOX_PASSWORD="${NHQ_INFOBLOX_PASS}"
        ;;
      enterprise)
        export GRID_URL="https://10.186.164.10"
        export GRID_HOST="entgridmgr.amfam.com"
        export GRID_HOST_IP="10.186.164.10"
        export INFOBLOX_USERNAME="${ENT_INFOBLOX_USER}"
        export INFOBLOX_PASSWORD="${ENT_INFOBLOX_PASS}"
        ;;
      *)
        echo "Unknown environment: $[[ inputs.environment ]]"
        exit 1
        ;;
    esac

    export RECORD_TYPE="$[[ inputs.record_type ]]"
    export OPERATION_TYPE="$[[ inputs.operation_type ]]"
    echo "Selected environment: $[[ inputs.environment ]]"
    echo "Selected record type: $RECORD_TYPE"
    echo "Selected operation: $OPERATION_TYPE"
    echo "Using Grid URL: $GRID_URL"
    echo "Using Grid Host: $GRID_HOST"

build_container:
  stage: build-container
  image:
    name: gcr.io/kaniko-project/executor:v1.9.0-debug
    entrypoint: [""]
  script:
    - |
      mkdir -p /kaniko/.docker
      echo "{\"auths\":{\"$CI_REGISTRY\":{\"auth\":\"$(printf "%s:%s" "${CI_REGISTRY_USER}" "${CI_REGISTRY_PASSWORD}" | base64 | tr -d '\n')\"}}}" > /kaniko/.docker/config.json

      echo "Building custom Infoblox runner container with Kaniko..."

      /kaniko/executor \
        --context "${CI_PROJECT_DIR}" \
        --dockerfile "${CI_PROJECT_DIR}/Dockerfile" \
        --destination "${CI_REGISTRY_IMAGE}/infoblox-runner:latest" \
        --cache=true \
        --cache-ttl=168h

      echo "Container built and pushed successfully"
  rules:
    - if: $CI_PIPELINE_SOURCE == 'web'
      changes:
        - Dockerfile
      when: always
    - if: $CI_PIPELINE_SOURCE == 'web'
      when: manual
    - when: never
  tags:
    - aws-eks-elz-ent-ens-01-01

file_processing:
  stage: file-processing
  script:
    - *common_script
    - |
      echo "=========================================="
      echo "  INFOBLOX RECORD PROCESSING PIPELINE"
      echo "=========================================="
      echo "Target Grid: $GRID_HOST"
      echo "Record Type: $RECORD_TYPE"
      echo "Operation: $OPERATION_TYPE"
      echo "Pipeline ID: ${CI_PIPELINE_ID}"
      echo "=========================================="
      echo ""

      echo "[1/5] Installing dependencies..."
      pip3 install pandas openpyxl >/dev/null 2>&1

      echo "[2/5] Validating input data..."
      if [ -z "$CSV_DATA" ]; then
        echo ""
        echo "ERROR: CSV_DATA is empty!"
        echo ""
        echo "Please provide CSV data with headers."
        echo ""
        echo "Expected format:"
        echo "----------------------------------------"
        echo "name,ipv4addr,view,comment,Environment,Owner,Location,Department"
        echo "webserver1.example.com,192.168.1.10,production,Web server,prod,teamA,DataCenter1,IT"
        echo "----------------------------------------"
        echo ""
        exit 1
      fi

      char_count=$(echo -n "$CSV_DATA" | wc -c)
      echo "   Input size: $char_count characters"

      CHAR_LIMIT=10000
      if [ $char_count -gt $CHAR_LIMIT ]; then
        echo ""
        echo "ERROR: Input exceeds character limit!"
        echo "   Current: $char_count characters"
        echo "   Maximum: $CHAR_LIMIT characters"
        echo "   Excess: $((char_count - CHAR_LIMIT)) characters"
        echo ""
        exit 1
      fi

      echo "[3/5] Saving CSV data..."
      mkdir -p input
      csv_file="input/${RECORD_TYPE}.csv"
      echo "$CSV_DATA" > "$csv_file"

      echo "DEBUG: Raw CSV content:"
      echo "----------------------------------------"
      cat "$csv_file" | head -5
      echo "----------------------------------------"

      echo "DEBUG: Checking CSV structure..."
      python3 -c "import csv; f=open('$csv_file','r'); reader=csv.DictReader(f,delimiter=','); print('Detected fields:',list(reader.fieldnames)); [print(f'Row {i+2}:',dict(row)) for i,row in enumerate(reader) if i<2]; f.close()"

      echo "[4/5] Input data preview:"
      echo "----------------------------------------"
      head -5 "$csv_file"
      if [ $(wc -l < "$csv_file") -gt 5 ]; then
        echo "... (showing first 5 lines)"
      fi
      echo "----------------------------------------"
      echo ""

      echo "[5/5] Processing records..."
      python3 infoblox_mvp1/utils/infoblox_record_processor.py \
        "$csv_file" \
        --grid-host "$GRID_HOST" \
        --record-type "$RECORD_TYPE" \
        --output-dir "infoblox_mvp1/prod_changes"

      if [ $? -ne 0 ]; then
        echo "  [ERROR] Failed to process $RECORD_TYPE"
        exit 1
      fi

      json_file="infoblox_mvp1/prod_changes/$GRID_HOST/${RECORD_TYPE}.json"
      if [ -f "$json_file" ]; then
        processed_count=$(python3 -c "import json; print(len(json.load(open('$json_file'))))")
        echo ""
        echo "=========================================="
        echo "  PROCESSING COMPLETE"
        echo "=========================================="
        echo "Processed: $processed_count records"
        echo "Output file: $json_file"
        echo "Record type: $RECORD_TYPE"
        echo "Target grid: $GRID_HOST"
        echo ""

        echo "JSON output preview:"
        echo "----------------------------------------"
        python3 -c "import json; import sys; data=json.load(open('$json_file')); print(json.dumps(data[:2] if len(data) > 2 else data, indent=2))"
        if [ $processed_count -gt 2 ]; then
          echo "... (showing first 2 records)"
        fi
        echo "----------------------------------------"
      else
        echo "[ERROR] JSON output file not created"
        exit 1
      fi

      echo "=========================================="

  artifacts:
    paths:
      - infoblox_mvp1/prod_changes/
      - input/
    expire_in: 1 hour
  tags:
    - aws-eks-elz-ent-ens-01-01

server_connection_test:
  stage: pre-implementation
  script:
    - *common_script
    - |
      echo "=== Network Connectivity Test ==="
      echo "Target Grid: $GRID_HOST ($GRID_HOST_IP)"

      if ! command -v curl > /dev/null 2>&1; then
        echo "Installing curl..."
        apt-get update && apt-get install -y curl
      fi

      echo "Testing connectivity to $GRID_URL..."
      if curl -s -k --head --request GET "$GRID_URL/ui" | grep -E "200 OK|302 Found" > /dev/null; then
        echo "[OK] Grid manager is reachable"
        exit 0
      else
        echo "[ERROR] Grid manager is unreachable"
        echo "This may indicate network restrictions on the GitLab Runner."
        exit 1
      fi
  tags:
    - aws-eks-elz-ent-ens-01-01

pre_check:
  stage: pre-implementation
  script:
    - *common_script
    - |
      echo "=== Pre-Check Validation with Robot Framework ==="
      echo "Grid: $GRID_HOST"
      echo "Record Type: $RECORD_TYPE"
      echo "Pipeline ID: ${CI_PIPELINE_ID}"

      export infoblox_username="$INFOBLOX_USERNAME"
      export infoblox_password="$INFOBLOX_PASSWORD"

      json_file="infoblox_mvp1/prod_changes/$GRID_HOST/${RECORD_TYPE}.json"

      if [ ! -f "$json_file" ]; then
        echo "[ERROR] JSON file not found: $json_file"
        exit 1
      fi

      echo "Installing Robot Framework and dependencies..."
      pip3 install --upgrade pip
      pip3 install robotframework
      pip3 install robotframework-requests
      pip3 install robotframework-jsonlibrary

      echo "Waiting for installation to complete..."
      sleep 10

      export PATH="$HOME/.local/bin:$PATH"

      echo "Current PATH: $PATH"
      echo "Python packages location:"
      ls -la $HOME/.local/bin/ || echo "Local bin not found"

      echo "Verifying Robot Framework installation..."
      which robot || echo "Robot command location not found in PATH"
      robot --version || echo "Robot Framework not accessible"

      echo "Running pre-check validation with Robot Framework..."

      # Determine which test suite to run based on record type
      case "$RECORD_TYPE" in
        a_record)
          test_suite="infoblox_mvp1/tests/pre_check/a_record_validation.robot"
          ;;
        cname_record)
          test_suite="infoblox_mvp1/tests/pre_check/cname_record_validation.robot"
          ;;
        network)
          test_suite="infoblox_mvp1/tests/pre_check/network_validation.robot"
          ;;
        *)
          test_suite="infoblox_mvp1/tests/pre_check/"
          ;;
      esac

      echo "Checking for test suite: $test_suite"
      if [ ! -e "$test_suite" ]; then
        echo "[WARNING] Test suite not found: $test_suite"
      fi

      echo "Running test suite: $test_suite"

      # Create output directory
      mkdir -p infoblox_mvp1/robot_reports/pre_check

      # Initialize execution counter directory
      mkdir -p infoblox_mvp1/robot_reports/execution_counters

      # Run Robot Framework tests
      set +e  # Don't exit on error
      robot \
        --variable GRID_HOST:$GRID_HOST \
        --variable RECORD_TYPE:$RECORD_TYPE \
        --variable PIPELINE_ID:${CI_PIPELINE_ID} \
        --variable COUNTER_FILE:infoblox_mvp1/robot_reports/execution_counters/pre_check_counter.json \
        --pythonpath infoblox_mvp1/utils/robot \
        --outputdir infoblox_mvp1/robot_reports/pre_check \
        --output output.xml \
        --log log.html \
        --report report.html \
        --name "Pre-Check Validation - $RECORD_TYPE - Pipeline ${CI_PIPELINE_ID}" \
        --loglevel INFO \
        "$test_suite"

      robot_exit_code=$?
      set -e  # Re-enable exit on error

      echo ""
      echo "Generated test reports:"
      ls -la infoblox_mvp1/robot_reports/pre_check/ || echo "No reports found"

      echo ""
      echo "=========================================="
      echo "  MERGING HISTORICAL TEST REPORTS"
      echo "=========================================="
      python3 infoblox_mvp1/utils/robot/merge_reports.py pre_check 20

      merge_exit_code=$?

      if [ $merge_exit_code -eq 0 ]; then
        echo ""
        echo "✅ Test history merged successfully!"
        echo ""
        echo "📊 AVAILABLE REPORTS:"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo "  📄 Current Run:     infoblox_mvp1/robot_reports/pre_check/report.html"
        echo "  📈 HISTORY REPORT:  infoblox_mvp1/robot_reports/pre_check/combined_report.html ⭐"
        echo "  📂 History Data:    infoblox_mvp1/robot_reports/pre_check/history/"
        echo "  📊 Total Runs:      $(ls -1 infoblox_mvp1/robot_reports/pre_check/history/output_*.xml 2>/dev/null | wc -l)"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo ""
      else
        echo "[WARN] Failed to merge test history (non-critical)"
      fi

      echo ""
      echo "=== Committing Pre-Check Results to Repository ==="

      # Configure git
      git config --global user.name "GitLab_Runner"
      git config --global user.email "ens@amfam.com"

      # Pull latest changes
      git pull origin main || true

      # Add robot reports and execution counters
      git add -f infoblox_mvp1/robot_reports/pre_check/* || true
      git add -f infoblox_mvp1/robot_reports/execution_counters/* || true

      # Check if there are changes to commit
      if ! git diff --cached --quiet; then
        # Create commit message with execution stats
        total_executions=$(python3 -c "import json; import os; f='infoblox_mvp1/robot_reports/execution_counters/pre_check_counter.json'; print(sum(v['count'] for v in json.load(open(f)).values()) if os.path.exists(f) else 0)" 2>/dev/null || echo "N/A")

        if [ $robot_exit_code -ne 0 ]; then
          commit_msg="Pre-check FAILED: $GRID_HOST - $RECORD_TYPE [Pipeline: ${CI_PIPELINE_ID}] [Total Executions: $total_executions]"
        else
          commit_msg="Pre-check PASSED: $GRID_HOST - $RECORD_TYPE [Pipeline: ${CI_PIPELINE_ID}] [Total Executions: $total_executions]"
        fi

        git commit -m "$commit_msg"
        git remote set-url origin "https://GitLab_Runner:${GITLAB_CI_TOKEN}@${CI_SERVER_HOST}/${CI_PROJECT_PATH}.git"

        # Push with retry
        for i in 1 2 3; do
          if git push origin HEAD:main; then
            echo "[OK] Pre-check results committed to repository"
            break
          else
            echo "[WARN] Push attempt $i failed, retrying..."
            sleep 2
            git pull --rebase origin main || true
          fi
        done
      else
        echo "[INFO] No new test results to commit"
      fi

      # Check if tests failed and exit accordingly
      if [ $robot_exit_code -ne 0 ]; then
        echo ""
        echo "=========================================="
        echo "[ERROR] Pre-check validation failed"
        echo "=========================================="
        echo "Test reports saved to: infoblox_mvp1/robot_reports/pre_check/"
        exit 1
      fi

      echo "[OK] Pre-check validation passed"

  artifacts:
    when: always
    paths:
      - infoblox_mvp1/robot_reports/pre_check/
      - infoblox_mvp1/robot_reports/execution_counters/
    expire_in: 1 week
  tags:
    - aws-eks-elz-ent-ens-01-01

json_validation:
  stage: pre-implementation
  script:
    - *common_script
    - |
      echo "=== JSON Validation ==="
      echo "Record type: $RECORD_TYPE"

      json_file="infoblox_mvp1/prod_changes/$GRID_HOST/${RECORD_TYPE}.json"

      # Check if file exists
      if [ ! -f "$json_file" ]; then
        echo "[ERROR] JSON file not found: $json_file"
        exit 1
      fi

      # Check if file is empty
      if [ ! -s "$json_file" ]; then
        echo "[ERROR] JSON file is empty"
        exit 1
      fi

      # Validate JSON
      if python3 -c "import json; json.load(open('$json_file'))"; then
        echo "✓ $json_file is valid JSON"
        record_count=$(python3 -c "import json; print(len(json.load(open('$json_file'))))")
        echo "  Records: $record_count"
      else
        echo "✗ $json_file is NOT valid JSON"
        exit 1
      fi

      echo ""
      echo "[OK] Validation passed"
  tags:
    - aws-eks-elz-ent-ens-01-01

run_ansible_playbook:
  stage: deploy
  needs:
    - file_processing
    - pre_check
    - json_validation
  script:
    - *common_script
    - |
      echo "=========================================="
      echo "  ANSIBLE DEPLOYMENT"
      echo "=========================================="
      echo "Grid: $GRID_HOST"
      echo "Record Type: $RECORD_TYPE"
      echo "Operation: $OPERATION_TYPE"
      echo "Pipeline ID: ${CI_PIPELINE_ID}"
      echo "=========================================="
      echo ""

      # Verify the JSON file exists and get absolute path
      json_file="infoblox_mvp1/prod_changes/$GRID_HOST/${RECORD_TYPE}.json"

      if [ ! -f "$json_file" ]; then
        echo "[ERROR] JSON file not found: $json_file"
        echo "Listing directory contents:"
        ls -la infoblox_mvp1/prod_changes/
        exit 1
      fi

      # Get absolute path for verification only
      JSON_FILE_PATH="$(pwd)/$json_file"
      echo "JSON file found at: $JSON_FILE_PATH"
      echo ""

      # Set relative path for Ansible playbook (relative to playbooks directory)
      ANSIBLE_JSON_PATH="../prod_changes/$GRID_HOST/${RECORD_TYPE}.json"

      export ANSIBLE_HOST_KEY_CHECKING=False
      export ANSIBLE_DEPRECATION_WARNINGS=False

      echo "Installing dependencies..."
      pip3 install --upgrade pip >/dev/null 2>&1
      pip3 install infoblox-client netaddr pyyaml requests urllib3 >/dev/null 2>&1

      mkdir -p ~/.ansible/collections/ansible_collections/infoblox/nios_modules/plugins/modules

      cat > provider_config.json << EOF
      {
        "clean_provider": {
          "host": "$GRID_HOST_IP",
          "username": "$INFOBLOX_USERNAME",
          "password": "$INFOBLOX_PASSWORD",
          "wapi_version": "2.13.4",
          "max_retries": 3,
          "max_results": 1000,
          "validate_certs": false,
          "http_request_timeout": 999999
        },
        "grid_host": "$GRID_HOST"
      }
      EOF

      echo ""

      playbook_file="infoblox_mvp1/playbooks/${RECORD_TYPE}.yml"

      if [ ! -f "$playbook_file" ]; then
        echo "[ERROR] Playbook not found: $playbook_file"
        exit 1
      fi

      echo "Executing playbook: $playbook_file"
      echo "Passing json_file variable: $ANSIBLE_JSON_PATH"
      echo ""

      ansible-playbook -i localhost, \
        --extra-vars "@provider_config.json" \
        -e "operation=$OPERATION_TYPE" \
        -e "json_file=$ANSIBLE_JSON_PATH" \
        -e "ansible_connection=local" \
        -e "ansible_python_interpreter=/usr/bin/python3" \
        "$playbook_file" \
        --verbose

      playbook_result=$?

      rm -f provider_config.json

      if [ $playbook_result -eq 0 ]; then
        echo ""
        echo "[OK] Deployment successful"
      else
        echo ""
        echo "[ERROR] Deployment failed"
        exit 1
      fi

      echo "=========================================="

  tags:
    - aws-eks-elz-ent-ens-01-01
  allow_failure: false

post_implementation:
  stage: post-implementation
  needs:
    - file_processing
    - run_ansible_playbook
  script:
    - *common_script
    - |
      echo "=== Post-Implementation Verification with Robot Framework ==="
      echo "Grid: $GRID_HOST"
      echo "Record Type: $RECORD_TYPE"
      echo "Operation: $OPERATION_TYPE"
      echo "Pipeline ID: ${CI_PIPELINE_ID}"

      export infoblox_username="$INFOBLOX_USERNAME"
      export infoblox_password="$INFOBLOX_PASSWORD"

      json_file="infoblox_mvp1/prod_changes/$GRID_HOST/${RECORD_TYPE}.json"

      if [ ! -f "$json_file" ]; then
        echo "[ERROR] JSON file not found: $json_file"
        exit 1
      fi

      record_count=$(python3 -c "import json; print(len(json.load(open('$json_file'))))")
      echo "Records to verify: $record_count"

      echo "Installing Robot Framework and dependencies..."
      pip3 install --upgrade pip
      pip3 install robotframework
      pip3 install robotframework-requests
      pip3 install robotframework-jsonlibrary

      echo "Waiting for installation to complete..."
      sleep 10

      export PATH="$HOME/.local/bin:$PATH"

      echo "Current PATH: $PATH"
      echo "Python packages location:"
      ls -la $HOME/.local/bin/ || echo "Local bin not found"

      echo "Verifying Robot Framework installation..."
      which robot || echo "Robot command location not found in PATH"
      robot --version || echo "Robot Framework not accessible"

      echo "Running post-implementation verification with Robot Framework..."

      # Determine which test suite to run based on record type
      case "$RECORD_TYPE" in
        a_record)
          test_suite="infoblox_mvp1/tests/post_check/a_record_verification.robot"
          ;;
        cname_record)
          test_suite="infoblox_mvp1/tests/post_check/cname_record_verification.robot"
          ;;
        network)
          test_suite="infoblox_mvp1/tests/post_check/network_verification.robot"
          ;;
        *)
          test_suite="infoblox_mvp1/tests/post_check/"
          ;;
      esac

      echo "Checking for test suite: $test_suite"
      if [ ! -e "$test_suite" ]; then
        echo "[WARNING] Test suite not found: $test_suite"
        echo "Creating a basic test file for validation..."
        mkdir -p infoblox_mvp1/tests/post_check
        cat > infoblox_mvp1/tests/post_check/basic_verification.robot << 'EOF'
      *** Settings ***
      Documentation    Basic Post-check Verification

      *** Variables ***
      ${GRID_HOST}    %{GRID_HOST}
      ${RECORD_TYPE}  %{RECORD_TYPE}

      *** Test Cases ***
      Basic Verification Test
          Log    Running basic post-check verification
          Log    Grid: ${GRID_HOST}
          Log    Record Type: ${RECORD_TYPE}
          Pass Execution    Basic verification completed
      EOF
        test_suite="infoblox_mvp1/tests/post_check/basic_verification.robot"
      fi

      echo "Running test suite: $test_suite"

      # Create output directory
      mkdir -p infoblox_mvp1/robot_reports/post_check
      mkdir -p infoblox_mvp1/robot_reports/execution_counters

      # Run Robot Framework tests
      set +e  # Don't exit on error
      robot \
        --variable GRID_HOST:$GRID_HOST \
        --variable RECORD_TYPE:$RECORD_TYPE \
        --variable OPERATION_TYPE:$OPERATION_TYPE \
        --variable PIPELINE_ID:${CI_PIPELINE_ID} \
        --variable COUNTER_FILE:infoblox_mvp1/robot_reports/execution_counters/post_check_counter.json \
        --pythonpath infoblox_mvp1/utils/robot \
        --outputdir infoblox_mvp1/robot_reports/post_check \
        --output output.xml \
        --log log.html \
        --report report.html \
        --name "Post-Implementation Verification - $RECORD_TYPE - Pipeline ${CI_PIPELINE_ID}" \
        --loglevel INFO \
        "$test_suite"

      robot_exit_code=$?
      set -e  # Re-enable exit on error

      echo ""
      echo "Generated test reports:"
      ls -la infoblox_mvp1/robot_reports/post_check/ || echo "No reports found"

      echo ""
      echo "=========================================="
      echo "  MERGING HISTORICAL TEST REPORTS"
      echo "=========================================="
      python3 infoblox_mvp1/utils/robot/merge_reports.py post_check 20

      merge_exit_code=$?

      if [ $merge_exit_code -eq 0 ]; then
        echo ""
        echo "✅ Test history merged successfully!"
        echo ""
        echo "📊 AVAILABLE REPORTS:"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo "  📄 Current Run:     infoblox_mvp1/robot_reports/post_check/report.html"
        echo "  📈 HISTORY REPORT:  infoblox_mvp1/robot_reports/post_check/combined_report.html ⭐"
        echo "  📂 History Data:    infoblox_mvp1/robot_reports/post_check/history/"
        echo "  📊 Total Runs:      $(ls -1 infoblox_mvp1/robot_reports/post_check/history/output_*.xml 2>/dev/null | wc -l)"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo ""
      else
        echo "[WARN] Failed to merge test history (non-critical)"
      fi

      echo ""
      echo "=== Committing Post-Check Results to Repository ==="

      # Configure git
      git config --global user.name "GitLab_Runner"
      git config --global user.email "ens@amfam.com"

      # Pull latest changes
      git pull origin main || true

      # Add robot reports and execution counters
      git add -f infoblox_mvp1/robot_reports/post_check/* || true
      git add -f infoblox_mvp1/robot_reports/execution_counters/* || true

      # Check if there are changes to commit
      if ! git diff --cached --quiet; then
        # Create commit message with execution stats
        total_executions=$(python3 -c "import json; import os; f='infoblox_mvp1/robot_reports/execution_counters/post_check_counter.json'; print(sum(v['count'] for v in json.load(open(f)).values()) if os.path.exists(f) else 0)" 2>/dev/null || echo "N/A")

        if [ $robot_exit_code -ne 0 ]; then
          commit_msg="Post-implementation FAILED: $GRID_HOST - $RECORD_TYPE - $OPERATION_TYPE [Pipeline: ${CI_PIPELINE_ID}] [Total Executions: $total_executions]"
        else
          commit_msg="Post-implementation PASSED: $GRID_HOST - $RECORD_TYPE - $OPERATION_TYPE [Pipeline: ${CI_PIPELINE_ID}] [Total Executions: $total_executions]"
        fi

        git commit -m "$commit_msg"
        git remote set-url origin "https://GitLab_Runner:${GITLAB_CI_TOKEN}@${CI_SERVER_HOST}/${CI_PROJECT_PATH}.git"

        # Push with retry
        for i in 1 2 3; do
          if git push origin HEAD:main; then
            echo "[OK] Post-implementation results committed to repository"
            break
          else
            echo "[WARN] Push attempt $i failed, retrying..."
            sleep 2
            git pull --rebase origin main || true
          fi
        done
      else
        echo "[INFO] No new test results to commit"
      fi

      # File cleanup section
      echo ""
      echo "=== File Cleanup and Repository Update ==="

      # Pull again in case of concurrent changes
      git pull origin main || true

      # Run file cleanup script if it exists
      if [ -f "infoblox_mvp1/utils/clearfilecontent.py" ]; then
        echo "Running file cleanup for $GRID_HOST..."
        python3 infoblox_mvp1/utils/clearfilecontent.py || true

        # Commit cleanup changes separately
        git add -A

        if ! git diff --cached --quiet; then
          git commit -m "Post-implementation cleanup for $GRID_HOST environment [Pipeline: ${CI_PIPELINE_ID}]"

          # Push with retry logic
          for i in 1 2 3; do
            if git push origin HEAD:main; then
              echo "[OK] Cleanup changes committed and pushed"
              break
            else
              echo "[WARN] Push attempt $i failed, retrying..."
              sleep 2
              git pull --rebase origin main || true
            fi
          done
        else
          echo "[INFO] No cleanup changes to commit"
        fi
      fi

      # Check if tests failed and exit accordingly
      if [ $robot_exit_code -ne 0 ]; then
        echo ""
        echo "=========================================="
        echo "[WARNING] Post-implementation verification had failures"
        echo "=========================================="
        echo "Test reports saved to: infoblox_mvp1/robot_reports/post_check/"
      else
        echo "[OK] Post-implementation verification passed"
      fi

      echo ""
      echo "Summary:"
      echo "  - Grid: $GRID_HOST"
      echo "  - Record Type: $RECORD_TYPE"
      echo "  - Operation: $OPERATION_TYPE"
      echo "  - Reports: infoblox_mvp1/robot_reports/post_check/"
      echo "  - Direct link: ${CI_PROJECT_URL}/-/tree/main/infoblox_mvp1/robot_reports/post_check"

  artifacts:
    when: always
    paths:
      - infoblox_mvp1/robot_reports/post_check/
      - infoblox_mvp1/robot_reports/execution_counters/
    expire_in: 1 week
  tags:
    - aws-eks-elz-ent-ens-01-01

generate_execution_report:
  stage: post-implementation
  needs:
    - post_implementation
  when: always
  script:
    - *common_script
    - |
      echo ""
      echo "=========================================="
      echo "  EXECUTION STATISTICS REPORT"
      echo "=========================================="
      echo "Grid: $GRID_HOST"
      echo "Record Type: $RECORD_TYPE"
      echo "Operation: $OPERATION_TYPE"
      echo "Pipeline ID: ${CI_PIPELINE_ID}"
      echo "=========================================="
      echo ""

      # Configure git FIRST before any operations
      git config --global user.name "GitLab_Runner"
      git config --global user.email "ens@amfam.com"
      
      # Set pull strategy to avoid divergent branches warning
      git config --global pull.rebase true
      
      # Fetch and reset to ensure clean state
      echo "Syncing with remote repository..."
      git fetch origin main
      git reset --hard origin/main
      
      # Now generate the report
      export GRID_HOST="$GRID_HOST"
      export RECORD_TYPE="$RECORD_TYPE"
      export OPERATION_TYPE="$OPERATION_TYPE"
      export CI_PIPELINE_ID="$CI_PIPELINE_ID"

      python3 infoblox_mvp1/utils/generate_execution_report.py

      echo ""
      echo "=========================================="
      echo "  REPORT GENERATION COMPLETE"
      echo "=========================================="
      echo "Execution Summary: infoblox_mvp1/robot_reports/execution_summary.html"
      echo "View at: ${CI_PROJECT_URL}/-/blob/main/infoblox_mvp1/robot_reports/execution_summary.html"
      echo "=========================================="

      # Add and commit the execution summary report
      git add -f infoblox_mvp1/robot_reports/execution_summary.html || true

      if ! git diff --cached --quiet; then
        git commit -m "Update execution statistics report [Pipeline: ${CI_PIPELINE_ID}]"
        git remote set-url origin "https://GitLab_Runner:${GITLAB_CI_TOKEN}@${CI_SERVER_HOST}/${CI_PROJECT_PATH}.git"

        # Pull with rebase to handle any concurrent changes
        git pull --rebase origin main || true

        # Push with retry
        for i in 1 2 3; do
          if git push origin HEAD:main; then
            echo "[OK] Execution summary committed to repository"
            break
          else
            echo "[WARN] Push attempt $i failed, retrying..."
            sleep 2
            git pull --rebase origin main || true
          fi
        done
      else
        echo "[INFO] No changes to execution summary"
      fi

  artifacts:
    when: always
    paths:
      - infoblox_mvp1/robot_reports/execution_summary.html
    expire_in: 1 week
  tags:
    - aws-eks-elz-ent-ens-01-01
    