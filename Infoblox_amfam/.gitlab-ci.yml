# .gitlab-ci.yml
# Enhanced GitLab CI configuration with Playbook Selector and CSV Input

spec:
  inputs:
    environment:
      type: string
      description: "Select the Grid environment to deploy to"
      default: "cabgridmgr"
      options:
        - "cabgridmgr"
        - "etsl"
        - "nhq"
        - "enterprise"
---
image: $CI_REGISTRY_IMAGE/infoblox-runner:latest

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"

  # Multiple Record Types Support (no longer needed - detected from CSV data)
  # RECORD_TYPE is now automatically detected from CSV prefixes

  OPERATION_TYPE:
    value: "add"
    options:
      - "add"
      - "delete"
    description: "Select operation: add (present state) or delete (absent state)"

  # CSV Data Input - Supports Multiple Record Types
  CSV_DATA:
    value: ""
    description: |
      Paste CSV data with record type prefix on each line.
      Format: record_type,column1,column2,column3,...

      Single Record Type Example:
      a_record,webserver1.example.com,192.168.1.10,production,Web server
      a_record,dbserver1.example.com,192.168.1.11,production,Database

      Multiple Record Types Example:
      a_record,server1.example.com,192.168.1.10,production,Web server
      a_record,server2.example.com,192.168.1.11,production,App server
      cname_record,www.example.com,server1.example.com,production,Website
      cname_record,api.example.com,server2.example.com,production,API
      host_record,mail.example.com,production,192.168.1.50,Mail server

      Available record types:
      a_record, aaaa_record, cname_record, fixed_address, host_record,
      mx_record, network, ptr_record, network_range, srv_record,
      txt_record, nios_zone

      Max: 10000 characters.
      Column order is flexible - processor maps by column name.
      No need to follow any specific order for record types.

stages:
  - build-container
  - file-processing
  - pre-implementation
  - validation-checkpoint
  - deploy
  - post-implementation

# Ensures the pipeline only runs when triggered manually
workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == 'web'
      when: always
    - when: never

# Build and cache custom container with all dependencies
build_container:
  stage: build-container
  image:
    name: gcr.io/kaniko-project/executor:v1.9.0-debug
    entrypoint: [""]
  script:
    - |
      # Create docker config for registry authentication
      mkdir -p /kaniko/.docker
      echo "{\"auths\":{\"$CI_REGISTRY\":{\"auth\":\"$(printf "%s:%s" "${CI_REGISTRY_USER}" "${CI_REGISTRY_PASSWORD}" | base64 | tr -d '\n')\"}}}" > /kaniko/.docker/config.json

      echo "Building custom Infoblox runner container with Kaniko..."

      # Build and push using kaniko
      /kaniko/executor \
        --context "${CI_PROJECT_DIR}" \
        --dockerfile "${CI_PROJECT_DIR}/Dockerfile" \
        --destination "${CI_REGISTRY_IMAGE}/infoblox-runner:latest" \
        --cache=true \
        --cache-ttl=168h

      echo "Container built and pushed successfully"
  rules:
    - if: $CI_PIPELINE_SOURCE == 'web'
      changes:
        - Dockerfile
      when: always
    - if: $CI_PIPELINE_SOURCE == 'web'
      when: manual
    - when: never
  tags:
    - aws-eks-elz-ent-ens-01-01

# Enhanced File Processing Stage
file_processing:
  stage: file-processing
  script:
    - *common_script
    - |
      echo "=========================================="
      echo "  INFOBLOX RECORD PROCESSING PIPELINE"
      echo "=========================================="
      echo "Target Grid: $GRID_HOST"
      echo "Operation: $OPERATION_TYPE"
      echo "=========================================="
      echo ""

      # Install required Python packages
      echo "[1/6] Installing dependencies..."
      pip3 install pandas openpyxl >/dev/null 2>&1

      # Validate CSV_DATA input
      echo "[2/6] Validating input data..."
      if [ -z "$CSV_DATA" ]; then
        echo ""
        echo "ERROR: CSV_DATA is empty!"
        echo ""
        echo "Please provide CSV data with record type prefix."
        echo ""
        echo "Expected format:"
        echo "----------------------------------------"
        echo "record_type,column1,column2,column3,..."
        echo ""
        echo "Example:"
        echo "a_record,server1.example.com,192.168.1.10,production,Web server"
        echo "cname_record,www.example.com,server1.example.com,production,Website"
        echo "----------------------------------------"
        echo ""
        exit 1
      fi

      # Check character limit
      char_count=$(echo -n "$CSV_DATA" | wc -c)
      echo "   Input size: $char_count characters"

      CHAR_LIMIT=10000
      if [ $char_count -gt $CHAR_LIMIT ]; then
        echo ""
        echo "ERROR: Input exceeds character limit!"
        echo "   Current: $char_count characters"
        echo "   Maximum: $CHAR_LIMIT characters"
        echo "   Excess: $((char_count - CHAR_LIMIT)) characters"
        echo ""
        exit 1
      fi

      # Parse and group records by type
      echo "[3/6] Parsing and grouping records by type..."
      mkdir -p input

      # Create a Python script to parse prefixed CSV
      cat > parse_csv.py << 'PYEOF'
import sys
from collections import defaultdict

csv_data = sys.stdin.read()
records_by_type = defaultdict(list)

for line in csv_data.strip().split('\n'):
    if not line.strip():
        continue
    parts = line.split(',', 1)
    if len(parts) < 2:
        print(f"Warning: Skipping invalid line: {line}", file=sys.stderr)
        continue

    record_type = parts[0].strip()
    record_data = parts[1].strip()
    records_by_type[record_type].append(record_data)

# Output grouped records
for record_type, records in records_by_type.items():
    print(f"{record_type}|{len(records)}")

# Save to separate files
import os
for record_type, records in records_by_type.items():
    filename = f"input/{record_type}.csv"
    with open(filename, 'w') as f:
        f.write('\n'.join(records))
    print(f"Created: {filename}", file=sys.stderr)
PYEOF

      # Parse CSV data
      echo "$CSV_DATA" | python3 parse_csv.py > record_summary.txt 2>parse_log.txt

      cat parse_log.txt
      echo ""

      # Display summary
      echo "Record type summary:"
      echo "----------------------------------------"
      cat record_summary.txt
      echo "----------------------------------------"
      echo ""

      # Store record types for later stages
      record_types=$(cat record_summary.txt | cut -d'|' -f1 | tr '\n' ',' | sed 's/,$//')
      echo "$record_types" > detected_record_types.txt
      echo "Detected record types: $record_types"
      echo ""

      # Show file preview
      echo "[4/6] Input data preview:"
      echo "----------------------------------------"
      for csv_file in input/*.csv; do
        if [ -f "$csv_file" ]; then
          echo "File: $(basename $csv_file)"
          head -3 "$csv_file"
          echo ""
        fi
      done
      echo "----------------------------------------"
      echo ""

      # Process each record type
      echo "[5/6] Processing records..."
      for csv_file in input/*.csv; do
        if [ ! -f "$csv_file" ]; then
          continue
        fi

        record_type=$(basename "$csv_file" .csv)
        echo ""
        echo "Processing: $record_type"
        echo "  File: $csv_file"

        python3 utils/infoblox_record_processor.py \
          "$csv_file" \
          --grid-host "$GRID_HOST" \
          --record-type "$record_type"

        if [ $? -ne 0 ]; then
          echo "  [ERROR] Failed to process $record_type"
          exit 1
        fi
        echo "  [OK] Success"
      done

      echo ""
      echo "=========================================="
      echo "  PROCESSING COMPLETE"
      echo "=========================================="
      echo "Generated files:"
      find prod_changes/$GRID_HOST -name "*.json" -type f
      echo ""
      echo "Records will be deployed to: $GRID_HOST"
      echo "Playbooks to execute:"
      for rtype in $(echo $record_types | tr ',' ' '); do
        echo "  - playbooks/nios_${rtype}.yml"
      done
      echo "=========================================="

  artifacts:
    paths:
      - prod_changes/
      - input/
      - detected_record_types.txt
    expire_in: 1 hour
  tags:
    - aws-eks-elz-ent-ens-01-01

# Common script section for 4-grid support
.common_script: &common_script
  - |
    echo "Starting Common Script"
    echo "Environment input: $[[ inputs.environment ]]"

    # Set GRID_HOST environment variable
    case "$[[ inputs.environment ]]" in
      cabgridmgr)
        export GRID_URL="https://10.74.3.80"
        export GRID_HOST="cabgridmgr.amfam.com"
        export GRID_HOST_IP="10.74.3.80"
        export INFOBLOX_USERNAME="${CAB_INFOBLOX_USER}"
        export INFOBLOX_PASSWORD="${CAB_INFOBLOX_PASS}"
        ;;
      etsl)
        export GRID_URL="https://172.24.125.10"
        export GRID_HOST="172.24.125.10"
        export GRID_HOST_IP="172.24.125.10"
        export INFOBLOX_USERNAME="${ETSL_INFOBLOX_USER}"
        export INFOBLOX_PASSWORD="${ETSL_INFOBLOX_PASS}"
        ;;
      nhq)
        export GRID_URL="https://10.74.70.63"
        export GRID_HOST="gridmgr.amfam.com"
        export GRID_HOST_IP="10.74.70.63"
        export INFOBLOX_USERNAME="${NHQ_INFOBLOX_USER}"
        export INFOBLOX_PASSWORD="${NHQ_INFOBLOX_PASS}"
        ;;
      enterprise)
        export GRID_URL="https://10.186.164.10"
        export GRID_HOST="entgridmgr.amfam.com"
        export GRID_HOST_IP="10.186.164.10"
        export INFOBLOX_USERNAME="${ENT_INFOBLOX_USER}"
        export INFOBLOX_PASSWORD="${ENT_INFOBLOX_PASS}"
        ;;
      *)
        echo "Unknown environment: $[[ inputs.environment ]]"
        exit 1
        ;;
    esac

    echo "Selected environment: $[[ inputs.environment ]]"
    echo "Using Grid URL: $GRID_URL"
    echo "Using Grid Host: $GRID_HOST"
    echo "GRID_HOST variable set for scripts: $GRID_HOST"

server_connection_test:
  stage: pre-implementation
  script:
    - *common_script
    - |
      echo "=== Network Connectivity Test ==="
      echo "Target Grid: $GRID_HOST ($GRID_HOST_IP)"

      # Ensure curl is installed
      if ! command -v curl > /dev/null 2>&1; then
        echo "Installing curl..."
        apt-get update && apt-get install -y curl
      fi

      # Test connectivity
      echo "Testing connectivity to $GRID_URL..."
      if curl -s -k --head --request GET "$GRID_URL/ui" | grep -E "200 OK|302 Found" > /dev/null; then
        echo "[OK] Grid manager is reachable"
        exit 0
      else
        echo "[ERROR] Grid manager is unreachable"
        echo "This may indicate network restrictions on the GitLab Runner."
        exit 1
      fi
  tags:
    - aws-eks-elz-ent-ens-01-01

# JSON validation for multiple record types
json_validation:
  stage: pre-implementation
  script:
    - *common_script
    - |
      echo "=== JSON Validation ==="

      # Load detected record types
      if [ ! -f "detected_record_types.txt" ]; then
        echo "[ERROR] detected_record_types.txt not found"
        exit 1
      fi

      record_types=$(cat detected_record_types.txt)
      echo "Validating record types: $record_types"
      echo ""

      total_records=0
      validation_failed=0

      for record_type in $(echo $record_types | tr ',' ' '); do
        echo "Validating: $record_type"
        json_file="prod_changes/$GRID_HOST/${record_type}.json"

        if [ ! -f "$json_file" ]; then
          echo "  [ERROR] JSON file not found: $json_file"
          validation_failed=1
          continue
        fi

        if [ ! -s "$json_file" ]; then
          echo "  [ERROR] JSON file is empty"
          validation_failed=1
          continue
        fi

        if python3 -c "import json; json.load(open('$json_file'))" 2>/dev/null; then
          record_count=$(python3 -c "import json; print(len(json.load(open('$json_file'))))")
          echo "  [OK] Valid JSON with $record_count record(s)"
          total_records=$((total_records + record_count))
        else
          echo "  [ERROR] Invalid JSON format"
          validation_failed=1
        fi
        echo ""
      done

      echo "=========================================="
      echo "Validation Summary:"
      echo "  Total record types: $(echo $record_types | tr ',' ' ' | wc -w)"
      echo "  Total records: $total_records"
      echo "=========================================="

      if [ $validation_failed -eq 1 ]; then
        echo "[ERROR] Validation failed for one or more record types"
        exit 1
      fi

      echo "[OK] All validations passed"
  tags:
    - aws-eks-elz-ent-ens-01-01

# Validation checkpoint
validation_checkpoint:
  stage: validation-checkpoint
  script:
    - *common_script
    - |
      echo "==========================================================="
      echo "  PRE-IMPLEMENTATION VALIDATION COMPLETE"
      echo "==========================================================="
      echo "Grid: $GRID_HOST"

      if [ -f "detected_record_types.txt" ]; then
        record_types=$(cat detected_record_types.txt)
        echo "Record Types: $record_types"
      fi

      echo "Operation: $OPERATION_TYPE"
      echo ""
      echo "Ready to deploy. Run deployment stage manually to proceed."
      echo "==========================================================="
  tags:
    - aws-eks-elz-ent-ens-01-01
  when: on_success

# Enhanced Ansible playbook execution with multiple playbook support
run_ansible_playbook:
  stage: deploy
  script:
    - *common_script
    - |
      echo "=========================================="
      echo "  ANSIBLE DEPLOYMENT"
      echo "=========================================="
      echo "Grid: $GRID_HOST"
      echo "Operation: $OPERATION_TYPE"

      # Load detected record types
      if [ ! -f "detected_record_types.txt" ]; then
        echo "[ERROR] detected_record_types.txt not found"
        exit 1
      fi

      record_types=$(cat detected_record_types.txt)
      echo "Record Types: $record_types"
      echo "=========================================="
      echo ""

      # Set up Ansible environment
      export ANSIBLE_HOST_KEY_CHECKING=False
      export ANSIBLE_DEPRECATION_WARNINGS=False

      # Install required packages
      echo "Installing dependencies..."
      pip3 install --upgrade pip >/dev/null 2>&1
      pip3 install infoblox-client netaddr pyyaml requests urllib3 >/dev/null 2>&1

      # Setup Ansible collections
      mkdir -p ~/.ansible/collections/ansible_collections/infoblox/nios_modules/plugins/modules

      # Create provider configuration
      cat > provider_config.json << EOF
      {
        "clean_provider": {
          "host": "$GRID_HOST_IP",
          "username": "$INFOBLOX_USERNAME",
          "password": "$INFOBLOX_PASSWORD",
          "wapi_version": "2.13.4",
          "max_retries": 3,
          "max_results": 1000,
          "validate_certs": false,
          "http_request_timeout": 999999
        },
        "grid_host": "$GRID_HOST"
      }
      EOF

      echo ""

      # Execute playbooks for each record type
      deployment_failed=0
      success_count=0
      failed_count=0

      for record_type in $(echo $record_types | tr ',' ' '); do
        echo "=========================================="
        echo "Deploying: $record_type"
        echo "=========================================="

        playbook_file="playbooks/nios_${record_type}.yml"

        if [ ! -f "$playbook_file" ]; then
          echo "[ERROR] Playbook not found: $playbook_file"
          failed_count=$((failed_count + 1))
          deployment_failed=1
          echo ""
          continue
        fi

        echo "Playbook: $playbook_file"
        echo ""

        # Run the specific playbook for the record type
        ansible-playbook -i localhost, \
          --extra-vars "@provider_config.json" \
          -e "operation=$OPERATION_TYPE" \
          -e "ansible_connection=local" \
          -e "ansible_python_interpreter=/usr/bin/python3" \
          "$playbook_file" \
          --verbose

        playbook_result=$?

        if [ $playbook_result -eq 0 ]; then
          echo ""
          echo "[OK] $record_type deployment successful"
          success_count=$((success_count + 1))
        else
          echo ""
          echo "[ERROR] $record_type deployment failed"
          failed_count=$((failed_count + 1))
          deployment_failed=1
        fi

        echo ""
      done

      # Clean up sensitive files
      rm -f provider_config.json

      echo "=========================================="
      echo "  DEPLOYMENT SUMMARY"
      echo "=========================================="
      echo "Successful: $success_count"
      echo "Failed: $failed_count"
      echo "Total: $(echo $record_types | tr ',' ' ' | wc -w)"
      echo "=========================================="

      if [ $deployment_failed -eq 1 ]; then
        echo ""
        echo "[ERROR] One or more deployments failed"
        exit 1
      fi

      echo ""
      echo "[OK] All deployments successful"

  tags:
    - aws-eks-elz-ent-ens-01-01
  when: manual
  allow_failure: false

# Post-implementation cleanup
post_implementation:
  stage: post-implementation
  script:
    - *common_script
    - |
      echo "=== Post-Implementation Cleanup ==="
      echo "Grid: $GRID_HOST"

      if [ -f "detected_record_types.txt" ]; then
        record_types=$(cat detected_record_types.txt)
        echo "Record Types: $record_types"
      fi

      # Optional: Run post-check verification
      # Uncomment if you have post-check scripts
      # for record_type in $(echo $record_types | tr ',' ' '); do
      #   python3 utils/post_check.py --grid-host "$GRID_HOST" --record-type "$record_type"
      # done

      echo "[OK] Deployment complete"
      echo ""
      echo "Summary:"
      echo "  - Grid: $GRID_HOST"
      echo "  - Record Types: $record_types"
      echo "  - Operation: $OPERATION_TYPE"
      echo "  - Status: Success"

  tags:
    - aws-eks-elz-ent-ens-01-01
  when: on_success
  needs:
    - run_ansible_playbook
